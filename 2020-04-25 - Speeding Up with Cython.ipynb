{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speeding Up with Cython\n",
    "\n",
    "We should be able to use Cython to speed up our functions.\n",
    "\n",
    "We should also be able to work in 8-bit space - we are not worried about being exact.\n",
    "\n",
    "The only library we are using is numpy so we need to work out how to use Cython with Numpy. Here is an article - https://blog.paperspace.com/faster-numpy-array-processing-ndarray-cython/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Classes\n",
    "\n",
    "We have three core classes:\n",
    "* Covariance\n",
    "* Power Iterator\n",
    "* VPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariance\n",
    "\n",
    "We'll start with the ZeroMeanCovarianceUnit.\n",
    "\n",
    "Data:\n",
    "* Size - small integer 8-bit unsigned.\n",
    "* Count - we could limit to 255? (i.e. 8-bit unsigned) At the moment just runs upwards so would be large int.\n",
    "* Square Sum - Numpy L * L 2D array\n",
    "    * The data points x are 1D arrays of -1 to 1. \n",
    "    * x dot x.T results in an L by L matrix. Each i, j th entry is x_i * x_j. So min is -1 and max is 1. So x dot x.T is a 2D array which can be 3 bit (or two binary matrixes - one positive, one negative or one with abs and one with sign information).\n",
    "    * Without scaling the square sum is a 2D integer array where the maximum integer is equal to the number of iterations.\n",
    "    * If there are 256 iterations we go from 8-bit to 16-bit.\n",
    "    * The covariance matrix is the square sum divided by the count. If we have 255 iterations each value could be mulitples of 1/255 - if we have 145 iterations it will be multiples of 1/145.\n",
    "    \n",
    "    \n",
    "Can we have an assumed division in our covariance matrix and have it as modulo bit-length (e.g. 255)? NEED TO DEVELOP THIS. We have iteration batches of bit_length (e.g. 255). When we reach count = 256 we bit shift right (divide by 2) and add. Or if count is an 8-bit int when count = 255 we run and then reset count to 0. Hence, we have a fraction resolution set by bit_depth.\n",
    "\n",
    "This will limit though to adapting to recent signals - we give our old signal and our new signal equal weight - but if our recent signal is very different but we have a normally stable variation (e.g. staring at a light) this will cause our covariance matrix to change. \n",
    "\n",
    "To cope we can change the right shift amounts. E.g. more heavy right shifts decrease our resolution of our updates but increase our resolution of our historic data. Weighting each.\n",
    "\n",
    "A good question is do we need a 16-bit resolution or is a 8-bit resolution functional?\n",
    "\n",
    "*Is this related to our scale system?* We have different covariance matrices representing different scales and then when we want the covariance matrix we combine and divide? Only need 10 log2 matrices. Buffers over time.\n",
    "\n",
    "It is related to our time buffers and time series. The reconstruction is our covariance. See 2020-02-21 - Playing with Time Series Configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm:\n",
    "* On first run calculate SS as normal (or minus 0 - maybe minus 128)\n",
    "* At iteration = bit_depth:\n",
    "    * Add strata (our old buffer).\n",
    "    * PBT the values between 0 and 255 to create binary version.\n",
    "    * Add binary version to rolling sum for new strata.\n",
    "    * If iteration = 255^i send estimate back and subtract instead of 128?\n",
    "    \n",
    "This is very very similar to our binary estimation case and reconstruction of predicted input. Coincidence?!\n",
    "\n",
    "255^8 at 1Hz is 566 535 009 millennia. Even at 1MHz this would still be several millennia. (255^4)s in years is 133 years. CPU is 1200MHz. 1.2 * 10^9. for an approximate result, divide the time value by 3.154e+7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "472.36586735924993"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((255**8)/(1.2*(10**9)))/(3.154*(10**7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "487.39019429585585"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(((2**8)**8)/(1.2*(10**9)))/(3.154*(10**7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "487.39019429585585"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((2**64)/(1.2*(10**9)))/(3.154*(10**7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8524151661147055"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((255**7)/(1.2*(10**9)))/(3.154*(10**7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So 8 sets of buffers would give us enough for 472 years at full CPU cycles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "512/4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we initialise the square sums as 128? Hence, we can subtract them? And change them?\n",
    "\n",
    "Above 255 = 2^8 where 8 = bit depth so 8 stages at 255 is the same as 2^16. So the stages are 64/bit_depth with max 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "64\n",
      "62\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "bd = 68\n",
    "print(bd)\n",
    "if bd > 64: bd = 64\n",
    "print(bd)\n",
    "bd = 62\n",
    "print(bd)\n",
    "if bd > 64: bd = 64\n",
    "print(bd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Init if not 8 bit.\n",
    "```\n",
    "def __init__(self, size, bit_depth=8):\n",
    "        \"\"\"Initialise.\n",
    "\n",
    "        Args:\n",
    "            size: integer setting the 1D size of an input.\n",
    "            bit_depth: number of bits to store representations (multiple of 8) - max 64\n",
    "        \"\"\"\n",
    "        self.size = size\n",
    "        self.count = 0\n",
    "        # Set bit_depth modulo 8\n",
    "        if bit_depth > 64: bit_depth = 64\n",
    "        if bit_depth < 8: bit_depth = 8\n",
    "        stages = 64//bit_depth\n",
    "        # Initialise Square Sum\n",
    "        self.square_sums = np.ones(shape=(size, size, stages))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does this only have benefit if we actually start to think that our representation space is limited?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using Cython its often better to define lists as 1D numpy arrays. So let's start doing that.\n",
    "\n",
    "```cdef np.array[double, dim=1] x_array```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.zeros(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[127 183 235 207]\n",
      " [ 82 234 230  90]\n",
      " [178 115 193 226]\n",
      " [250 142 173 184]] [[171 228  30 215]\n",
      " [233 152 128 218]\n",
      " [141   9 252 124]\n",
      " [200  52 248  28]] [[0 0 1 0]\n",
      " [0 1 1 0]\n",
      " [1 1 0 1]\n",
      " [1 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Can we do 2D PBT?\n",
    "rand_vals_1 = np.random.randint(255, size=(4,4))\n",
    "rand_vals_2 = np.random.randint(255, size=(4,4))\n",
    "binary_values = np.where(rand_vals_1 > rand_vals_2, 1, 0)\n",
    "print(rand_vals_1, rand_vals_2, binary_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[128,   0,   1,   0],\n",
       "       [128,   1,   1,   0],\n",
       "       [128,   1,   0,   1],\n",
       "       [128,   1,   0,   1]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " binary_values[:, 0] = 128; binary_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "127//2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When ensuring that we remain within signed 8-bits integers we can divide by 2 before subtracting. But like our other residuals most of the energy is around the mean. So clipping maybe better. We thus clip at -64 and +63 subtract then times by 2.\n",
    "```\n",
    "# Right bit shift the current sum and the next stage sum\n",
    "            # BUT LIKE OUR RESIDUALS WE MIGHT FIND ITS BETTER TO CLIP THAN DIVIDE\n",
    "            current_stage = self.square_sum[:, :, 0]//2\n",
    "            next_stage = self.square_sum[:, :, 1]//2\n",
    "```\n",
    "\n",
    "Clipping will only work if our input signal is already zero mean - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version with 8-bit bit-depth\n",
    "class CovarianceUnit:\n",
    "    \"\"\"Variation where the mean is assumed to be 0.\"\"\"\n",
    "    \n",
    "    def __init__(self, size):\n",
    "        \"\"\"Initialise.\n",
    "\n",
    "        Args:\n",
    "            size: integer setting the 1D size of an input.\n",
    "        \"\"\"\n",
    "        self.size = size\n",
    "        # Set max value for signed int\n",
    "        self.max_value = 126\n",
    "        self.stages = 8\n",
    "        # Initialise Square Sums \n",
    "        self.square_sum = np.zeros(shape=(size, size, stages), dtype=np.int8)\n",
    "        # Set first set of square sums to -128\n",
    "        self.square_sum[:, :, 0] = -128\n",
    "        # Define counter for each stage\n",
    "        self.stage_counter = np.zeros(stages, dtype=np.uint8)\n",
    "        \n",
    "    def update(self, x):\n",
    "        \"\"\"Add a data point x.\n",
    "        \n",
    "        This will involve a recursive check.\n",
    "\n",
    "        x is a 1D numpy array of length 'size'.\n",
    "        \"\"\"\n",
    "        # Increment current stage counter\n",
    "        self.stage_counters[0] += 1\n",
    "        # Add square of input array\n",
    "        self.square_sum[:, :, 0] += np.dot(x, x.T)\n",
    "        self.recursive_update(0)\n",
    "                \n",
    "    def recursive_update(i):\n",
    "        \"\"\"Update with recursive method.\n",
    "        \n",
    "        Args:\n",
    "            i - stage to update - integer.\n",
    "        \"\"\"\n",
    "        # Check i is within range\n",
    "        if i > self.stages: \n",
    "            return\n",
    "        # If i is within range check counter\n",
    "        if self.stage_counters[i] >= 255:\n",
    "            # Right bit shift the current sum and the next stage sum\n",
    "            current_stage = self.square_sum[:, :, i]//2\n",
    "            next_stage = self.square_sum[:, :, i+1]//2\n",
    "            # Subtract estimate from next stage\n",
    "            square_sum_dash = current_stage - next_stage\n",
    "            # Clip at -64 and 63 then times by 2 - returns to int8 space\n",
    "            square_sum_dash = np.clip(square_sum_dash, -63, 63)*2\n",
    "            # PBT self.square_sum[:, :, 0] - BUT WILL THIS BE TERNARY? \n",
    "            rand_ints = np.random.randint(\n",
    "                self.max_value, size=(self.size, self.size)\n",
    "            )\n",
    "            signs = np.signs(square_sum_dash)\n",
    "            pbt_output = np.where(np.abs(square_sum_dash, rand_ints, 1, 0)\n",
    "            # Add to next stage (with signs returned)\n",
    "            self.square_sum[:, :, i+1] += pbt_output*signs\n",
    "            # Reset the previous counter\n",
    "            self.stage_counters[i] = 0\n",
    "            # Increment next stage counter\n",
    "            self.stage_counters[i+1] += 1\n",
    "            self.recursive_update(i+1)\n",
    "        else:\n",
    "            return\n",
    "                                  \n",
    "    @property\n",
    "    def covariance(self):\n",
    "        \"\"\"Compute covariance when requested.\"\"\"\n",
    "        # Reconstruct from square sums\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power Iteration\n",
    "\n",
    "We need to look at this next because we need to see how to return the covariance.\n",
    "\n",
    "For power iterator we have the following data:\n",
    "* ev - this is normally a float numpy 1D array with fractional values\n",
    "* cov - this is normally a float numpy 2D array \n",
    "* scaler - this will have a fractional value greater than 1 (normally greater than 1.4).\n",
    "\n",
    "We can keep ev and cov in signed 8 bit space and take the 1/127 out of the calculations (putting them at the front).\n",
    "\n",
    "We have:\n",
    "* cov^power \\* ev - we can take out (1/127)^2 if power = 1.\n",
    "* ev^T.input_data - we can take out (1/127) - input_data is -1, 0, 1 so so we have the same possible scale at ev but flipped - why we need symmetric scales - clip at -127 to 127.\n",
    "\n",
    "We can either operate in the next power of 2 space - e.g. 16 bit vs 8 bit - the result is stored in 16 bit space to represent a max of 128 \\* 128 (if signed - 255 if unsigned). OR. We can divide both the cov and the ev by 16 - so that the we have max 16\\*16 = 256 (right shift by 3). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PowerIterator:\n",
    "    \"\"\"Module to determine an eigenvector using power iteration.\"\"\"\n",
    "\n",
    "    def __init__(self, length):\n",
    "        \"\"\"Initialise.\n",
    "\n",
    "        Args:\n",
    "            length: integer setting the 1D size of the eigenvector.\n",
    "        \"\"\"\n",
    "        # Initialise eigenvector as random vector - NOTE 8 bit\n",
    "        # THIS WILL BE RANDOM ANYWAY DUE TO INHERENT RANDOMNESS\n",
    "        self.ev = np.zeros(shape=(length,1))\n",
    "        # Loop if we get all zeros\n",
    "        while not self.ev.any():\n",
    "            self.ev = np.random.randint(255, size=(length, 1))\n",
    "        # Scale to have unit length (convert to integer values?)\n",
    "        self.ev = self.ev / np.linalg.norm(self.ev)\n",
    "        # Define placeholder for covariance matrix\n",
    "        self.cov = np.zeros(shape=(length, length))\n",
    "        # Define scaling factor as 1/sqrt(length)\n",
    "        self.scaler = np.sqrt(length) / length\n",
    "\n",
    "    def iterate(self, power=1, cov=None):\n",
    "        \"\"\"One pass of iteration.\"\"\"\n",
    "        # If a covariance is passed use to update\n",
    "        if cov is not None:\n",
    "            self.load_covariance(cov)\n",
    "        # Check cov is not all zero - if all 0 you get nan\n",
    "        if self.cov.any():\n",
    "            # Times covariance by working eigenvector\n",
    "            if power == 1:\n",
    "                # Speed up for single power\n",
    "                self.ev = np.matmul(self.cov, self.ev)\n",
    "            else:\n",
    "                self.ev = np.matmul(np.power(self.cov, power), self.ev)\n",
    "            # Scale to have unit length (convert to integer values?)\n",
    "            self.ev = self.ev / np.linalg.norm(self.ev)\n",
    "        return self.ev.copy()\n",
    "\n",
    "    @property\n",
    "    def eigenvector(self):\n",
    "        \"\"\"Return the top eigenvector.\"\"\"\n",
    "        return self.ev.copy()\n",
    "\n",
    "    @property\n",
    "    def eigenvalue(self):\n",
    "        \"\"\"Return associated eigenvalue.\"\"\"\n",
    "        top_1 = np.matmul(self.ev.T, self.cov)\n",
    "        bottom = np.matmul(self.ev.T, self.ev)\n",
    "        r = np.matmul(top_1, self.ev) / bottom\n",
    "        return r\n",
    "\n",
    "    @property\n",
    "    def feature(self):\n",
    "        \"\"\"Return eigenvector scaled to ternary space.\"\"\"\n",
    "        return self.ev*self.scaler\n",
    "\n",
    "    def load_covariance(self, cov):\n",
    "        \"\"\"Update the covariance matrix.\"\"\"\n",
    "        self.cov = cov\n",
    "        # Put here an update of an existing matrix?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Reference Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version with variable bit depth\n",
    "class CovarianceUnit:\n",
    "    \"\"\"Variation where the mean is assumed to be 0.\"\"\"\n",
    "    \n",
    "    def __init__(self, size, bit_depth=8):\n",
    "        \"\"\"Initialise.\n",
    "\n",
    "        Args:\n",
    "            size: integer setting the 1D size of an input.\n",
    "            bit_depth: number of bits to store representations (multiple of 8) - max 64\n",
    "        \"\"\"\n",
    "        self.size = size\n",
    "        self.bit_depth = bit_depth\n",
    "        self.max_value = 2**bit_depth\n",
    "        # Set bit_depth modulo 8\n",
    "        if bit_depth > 64: bit_depth = 64\n",
    "        if bit_depth < 8: bit_depth = 8\n",
    "        stages = 64//bit_depth\n",
    "        # Set \n",
    "        # Initialise Square Sum\n",
    "        self.square_sum = np.ones(shape=(size, size, stages), dtype=)\n",
    "        # Set to halfway between 0 and bit depth (128 for 8-bit)\n",
    "        self.square_sum = 2**(bit_depth-1)*self.square_sum\n",
    "        # Define counter for each stage\n",
    "        self.stage_counter = np.zeros(stages)\n",
    "        \n",
    "    def update(self, x):\n",
    "        \"\"\"Add a data point x.\n",
    "        \n",
    "        This will involve a recursive check.\n",
    "\n",
    "        x is a 1D numpy array of length 'size'.\n",
    "        \"\"\"\n",
    "        self.stage_counters[0] += 1\n",
    "        self.square_sum[:, :, 0] += np.dot(x, x.T)\n",
    "        # If the count reaches a threshold, can we divide the sums\n",
    "        if self.stage_counters[0] >= (2**bit_depth)-1:\n",
    "            # Subtract estimate from next stage\n",
    "            square_sum_dash = self.square_sum[:, :, 0] - self.square_sum[:, :, 1]\n",
    "            # PBT self.square_sum[:, :, 0] - BUT WILL THIS BE TERNARY? \n",
    "            rand_ints = np.random.randint(\n",
    "                self.max_value, size=(self.size, self.size)\n",
    "            )\n",
    "            signs = np.signs(square_sum_dash)\n",
    "            pbt_output = np.where(self.square_sum[:, :, 0], rand_ints, 1, 0)\n",
    "            # Add to next stage\n",
    "            self.square_sum[:, :, 1] += pbt_output\n",
    "            # Increment next stage counter\n",
    "            self.stage_counters[1] += 1\n",
    "            # Reset the previous counter\n",
    "            self.stage_counters[0] = 0\n",
    "            if self.stage_counters[1] >= (2**bit_depth)-1:\n",
    "                \n",
    "\n",
    "    @property\n",
    "    def covariance(self):\n",
    "        \"\"\"Compute covariance when requested.\"\"\"\n",
    "        # Only return is count is 1 or more\n",
    "        if self.count:\n",
    "            cov = self.square_sum / self.count\n",
    "        else:\n",
    "            cov = self.square_sum\n",
    "        return cov\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
