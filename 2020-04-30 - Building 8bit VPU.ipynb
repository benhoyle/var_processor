{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion required:\n",
    "* In the forward processing below, the eigenvector is 8-bit and the input is ternary but represented in 8-bits. But the result may be bit_depth_max\\*L - actually as the eigenvector is normalised this will be int(1/sqrt(L))\\*127)\\*L.\n",
    "* In the backward processing, processed_r_back is ternary (but stored as 8-bit) and eigenvector is 8-bit as above. The result is either -1\\*eigenvector, 0 or eigenvector.\n",
    "* We can likely implement all casting control in the project method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.var_processor.covariance8bit import CovarianceUnit\n",
    "from src.var_processor.power_iterator8bit import PowerIterator\n",
    "from src.var_processor.pb_threshold import ternary_pbt\n",
    "\n",
    "def project(vec_1, vec_2):\n",
    "    \"\"\"Project input using eigenvector.\n",
    "\n",
    "    Args:\n",
    "        vec1: 1D numpy array.\n",
    "        vec2: 1D numpy array.\n",
    "    \"\"\"\n",
    "    return np.dot(vec_1, vec_2)\n",
    "\n",
    "\n",
    "class VPU:\n",
    "    \"\"\"Variance processing unit.\"\"\"\n",
    "\n",
    "    def __init__(self, size):\n",
    "        \"\"\"Initialise.\n",
    "\n",
    "        Args:\n",
    "            size: integer setting the 1D size of an input;\n",
    "        \"\"\"\n",
    "        self.cu = CovarianceUnit(size)\n",
    "        self.pi = PowerIterator(size)\n",
    "        self.size = size\n",
    "\n",
    "    def forward_processing(self, forward_data):\n",
    "        \"\"\"Process data to apply to forward input data.\"\"\"\n",
    "        return forward_data\n",
    "\n",
    "    def pred_input_processing(self, pred_inputs):\n",
    "        \"\"\"Process data to apply to output predicted inputs.\"\"\"\n",
    "        return pred_inputs\n",
    "\n",
    "    def r_forward_processing(self, r_forward):\n",
    "        \"\"\"Process data to apply to output r_forward value.\"\"\"\n",
    "        return r_forward\n",
    "\n",
    "    def r_backward_processing(self, r_backward):\n",
    "        \"\"\"Process data to apply to output r_forward value.\"\"\"\n",
    "        return r_backward\n",
    "\n",
    "    def iterate(self, forward_data, r_backward):\n",
    "        \"\"\"Iterate through one discrete timestep.\n",
    "\n",
    "        Args:\n",
    "            forward_data: data for feedforward transformation\n",
    "                1D numpy array of length self.size.\n",
    "            r_backward: scalar value indicating a prediction of r.\n",
    "\n",
    "        Returns:\n",
    "            pred_inputs: 1D array containing the predicted input\n",
    "            r: scalar feature detection output\n",
    "\n",
    "        \"\"\"\n",
    "        r_forward = self.forward(forward_data)\n",
    "        pred_inputs = self.backward(r_backward)\n",
    "        return r_forward, pred_inputs\n",
    "\n",
    "    def forward(self, forward_data):\n",
    "        \"\"\"Forward pass to generate cause - r.\n",
    "\n",
    "        Args:\n",
    "            forward_data: 1D numpy array of length self.size.\n",
    "            This is the residual data rather than the original data.\n",
    "        Returns:\n",
    "            r_forward: scalar feature detection output\n",
    "\n",
    "        \"\"\"\n",
    "        # Perform optional pre-processing\n",
    "        processed_data = self.forward_processing(forward_data)\n",
    "        # Project\n",
    "        r_forward = project(self.pi.eigenvector.T, processed_data)\n",
    "        # Perform optional post-processing\n",
    "        processed_output = self.r_forward_processing(r_forward)\n",
    "        return processed_output\n",
    "\n",
    "    def backward(self, r_backward):\n",
    "        \"\"\"Backward pass to generate predicted inputs.\n",
    "\n",
    "        The predicted inputs are the original not residual inputs.\n",
    "\n",
    "        Args:\n",
    "            r_backward: scalar cause feedback.\n",
    "        Returns:\n",
    "            pred_inputs: numpy array of predicted inputs of size - size.\n",
    "\n",
    "        \"\"\"\n",
    "        # Perform optional pre-processing\n",
    "        processed_r_back = self.r_backward_processing(r_backward)\n",
    "        # Use item to convert r to scalar\n",
    "        pred_inputs = project(processed_r_back.item(), self.pi.eigenvector)\n",
    "        # Perform optional post-processing\n",
    "        processed_output = self.pred_input_processing(pred_inputs)\n",
    "        return processed_output\n",
    "\n",
    "    def update_cov(self, input_data, power_iterate=False):\n",
    "        \"\"\"Update the covariance matrix.\n",
    "\n",
    "        Use this to bed in the covariance.\n",
    "\n",
    "        Args:\n",
    "            input_data: 1D numpy array of length self.size.\n",
    "            This is the original rather than residual data.\n",
    "        \"\"\"\n",
    "        self.cu.update_cov(input_data)\n",
    "        if power_iterate:\n",
    "            cov = self.cu.covariance\n",
    "            # Power iterate\n",
    "            self.pi.load_covariance(cov)\n",
    "            self.pi.iterate()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset and clear.\"\"\"\n",
    "        self.__init__(self.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Original VPU Tests on Above \n",
    "\n",
    "We'll now get integer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tests.test_vpu import rand_same, rand_diff, rand_opposite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[70 70]\n",
      " [70 70]] [[0.5511811 0.5511811]\n",
      " [0.5511811 0.5511811]]\n",
      "[[-89]\n",
      " [-89]] 89.80256121069152\n"
     ]
    }
   ],
   "source": [
    "vpu = VPU(2)\n",
    "for _ in range(0, 1000):\n",
    "    vpu.update_cov(rand_same(), power_iterate=True)\n",
    "# Check all values of covariance matrix are the same\n",
    "print(vpu.cu.covariance, vpu.cu.covariance/127)\n",
    "print(vpu.pi.eigenvector, (1/np.sqrt(2))*127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1]], dtype=int8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = np.ones(shape=(2,1), dtype=np.int8); ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[78]], dtype=int8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vpu.forward(ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-125]], dtype=int8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data = ones*(np.sqrt(2)/2)\n",
    "project(vpu.pi.eigenvector.T, processed_data).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-62]], dtype=int8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd = np.asarray([[1], [0]]); odd\n",
    "\n",
    "processed_data = odd*(np.sqrt(2)/2)\n",
    "project(vpu.pi.eigenvector.T, processed_data).astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([140], dtype=uint16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vpu.pi.eigenvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1053.0623, -1053.0623], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_1 = np.dot(vpu.pi.eigenvector, np.sqrt(vpu.pi.eigenvalue)); sample_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.73578079, -0.73578079])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_1 = np.dot(vpu.pi.eigenvector/127, np.sqrt(vpu.pi.eigenvalue/127)); sample_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[84 84]\n",
      " [84 84]] [[0.66141732 0.66141732]\n",
      " [0.66141732 0.66141732]]\n",
      "[[-89]\n",
      " [-89]] 89.80256121069152\n"
     ]
    }
   ],
   "source": [
    "vpu = VPU(2)\n",
    "for _ in range(0, 1000):\n",
    "    vpu.update_cov(rand_same(negative=True), power_iterate=True)\n",
    "# Check all values of covariance matrix are the same\n",
    "print(vpu.cu.covariance, vpu.cu.covariance/127)\n",
    "print(vpu.pi.eigenvector, (1/np.sqrt(2))*127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([168], dtype=uint16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vpu.pi.eigenvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.80600747, -0.80600747])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_1 = np.dot(vpu.pi.eigenvector/127, np.sqrt(vpu.pi.eigenvalue/127)); sample_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[77 77 77 77]\n",
      " [77 77 77 77]\n",
      " [77 77 77 77]\n",
      " [77 77 77 77]] [[0.60629921 0.60629921 0.60629921 0.60629921]\n",
      " [0.60629921 0.60629921 0.60629921 0.60629921]\n",
      " [0.60629921 0.60629921 0.60629921 0.60629921]\n",
      " [0.60629921 0.60629921 0.60629921 0.60629921]]\n",
      "[[63]\n",
      " [63]\n",
      " [63]\n",
      " [63]] 63.5\n"
     ]
    }
   ],
   "source": [
    "size = 4\n",
    "vpu = VPU(size)\n",
    "for _ in range(0, 1000):\n",
    "    vpu.update_cov(rand_same(negative=True, size=size), power_iterate=True)\n",
    "# Check all values of covariance matrix are the same\n",
    "print(vpu.cu.covariance, vpu.cu.covariance/127)\n",
    "print(vpu.pi.eigenvector, (np.sqrt(4)/4)*127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[63],\n",
       "       [63],\n",
       "       [63],\n",
       "       [63]], dtype=int8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vpu.pi.eigenvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "[[0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]]\n",
      "[[126.]]\n",
      "[[126]]\n"
     ]
    }
   ],
   "source": [
    "size = 4\n",
    "ones = np.ones(shape=(size,1), dtype=np.int8); print(ones)\n",
    "processed_data = ones*(np.sqrt(size)/size); print(processed_data)\n",
    "print(project(vpu.pi.eigenvector.T, processed_data))\n",
    "print(project(vpu.pi.eigenvector.T, processed_data).astype(np.int8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]]\n",
      "[[-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]]\n",
      "[[-126.]]\n",
      "[[-126]]\n"
     ]
    }
   ],
   "source": [
    "size = 4\n",
    "neg_ones = -1*np.ones(shape=(size,1), dtype=np.int8); print(neg_ones)\n",
    "processed_data = neg_ones*(np.sqrt(size)/size); print(processed_data)\n",
    "print(project(vpu.pi.eigenvector.T, processed_data))\n",
    "print(project(vpu.pi.eigenvector.T, processed_data).astype(np.int8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah - so this should be reversed sign and we are getting overflow. Our eigenvectors are one integer too big at -64 - should be -63. On the positive side we are still fine and have 63.\n",
    "\n",
    "We can now PBT with max value = 126."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-127//10.9, -127/10.9, 127//10.9, 127/10.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah that is why - integer rounds down for negative numbers. We need to adjust our normalise function. **FIXED** (By taking the sign out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryVPU(VPU):\n",
    "    \"\"\"Let's update our functions modularly.\"\"\"\n",
    "\n",
    "    def __init__(self, size):\n",
    "        \"\"\"Adapted Init.\"\"\"\n",
    "        super(BinaryVPU, self).__init__(size)\n",
    "        # Calculate scale factor here to save time later\n",
    "        self.scale_forward = np.sqrt(self.size)/self.size\n",
    "        self.scale_backward = self.size/np.sqrt(self.size)\n",
    "\n",
    "    def r_forward_processing(self, r_forward):\n",
    "        \"\"\"Scale r to -1 to 1 and PBT.\"\"\"\n",
    "        # Scale to ternary\n",
    "        scaled_r = r_forward*self.scale_forward\n",
    "        # Threshold r\n",
    "        binary_values = ternary_pbt(scaled_r)\n",
    "        return binary_values\n",
    "\n",
    "    def r_backward_processing(self, r_backward):\n",
    "        \"\"\"Rescale r to -L/sqrt(L) to L/sqrt(L) and PBT.\"\"\"\n",
    "        # Scale to ternary\n",
    "        scaled_r = r_backward*self.scale_backward\n",
    "        return scaled_r\n",
    "\n",
    "    def pred_input_processing(self, pred_inputs):\n",
    "        \"\"\"Apply PBT to get outputs in range -1, 0, 1.\"\"\"\n",
    "        binary_values = ternary_pbt(pred_inputs)\n",
    "        return binary_values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
