{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook looks at constructing some of the components to provide the variance processor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Covariance\n",
    "\n",
    "Based on the article here: https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance .\n",
    "\n",
    "In particular, Welford's online algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume our input data is a 1D array. We can always flatten before hand if not. We are calculating the mean and variance of the array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the Article for the 1D Case\n",
    "\n",
    "We need to convert the algorithm below to the ND case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a new value newValue, compute the new count, new mean, the new M2.\n",
    "# mean accumulates the mean of the entire dataset\n",
    "# M2 aggregates the squared distance from the mean\n",
    "# count aggregates the number of samples seen so far\n",
    "def update(existingAggregate, newValue):\n",
    "    (count, mean, M2) = existingAggregate\n",
    "    count += 1\n",
    "    delta = newValue - mean\n",
    "    mean += delta / count\n",
    "    delta2 = newValue - mean\n",
    "    M2 += delta * delta2\n",
    "\n",
    "    return (count, mean, M2)\n",
    "\n",
    "# Retrieve the mean, variance and sample variance from an aggregate\n",
    "def finalize(existingAggregate):\n",
    "    (count, mean, M2) = existingAggregate\n",
    "    (mean, variance, sampleVariance) = (mean, M2 / count, M2 / (count - 1))\n",
    "    if count < 2:\n",
    "        return float('nan')\n",
    "    else:\n",
    "        return (mean, variance, sampleVariance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_variance(avg_a, count_a, var_a, avg_b, count_b, var_b):\n",
    "    delta = avg_b - avg_a\n",
    "    m_a = var_a * (count_a - 1)\n",
    "    m_b = var_b * (count_b - 1)\n",
    "    M2 = m_a + m_b + delta ** 2 * count_a * count_b / (count_a + count_b)\n",
    "    return M2 / (count_a + count_b - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had when calculating U:\n",
    "```\n",
    "[In FOR loop]\n",
    "    x = x.reshape(x.shape[0], 1)\n",
    "    x_dash = x - mean\n",
    "    mean += (x_dash / count)\n",
    "    covariance += np.dot(x_dash, x_dash.T)\n",
    "                \n",
    "covariance = covariance / count\n",
    "```\n",
    "This is the same - only in the above update they substract the new mean while we substract the old mean. The finalize is also the same - just dividing the covariance by the count. As n gets large the sample covariance becomes indistinguishable from the actual. This will be the case for us as only a few seconds gets us hundreds of samples so n is 100.\n",
    "\n",
    "We need to be looking at classes as we can have the aggregate values as state.\n",
    "\n",
    "I think we can leave not removing the updated mean if we are dealing with large cound values (so the mean update will be small)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Covariance_Unit:\n",
    "    \"\"\"A model to compute covariance online.\"\"\"\n",
    "    def __init__(self, size):\n",
    "        \"\"\"Initialise.\n",
    "        \n",
    "        size is an integer setting the 1D size of an input.\"\"\"\n",
    "        self.size = size\n",
    "        self.count = 0\n",
    "        self.mean = np.zeros(shape=(size, 1))\n",
    "        self.square_sum = np.zeros(shape=(size, size))\n",
    "\n",
    "    def update(self, x):\n",
    "        \"\"\"Add a data point x.\n",
    "        \n",
    "        x is a 1D numpy array of length 'size'.\n",
    "        \"\"\"\n",
    "        self.count += 1\n",
    "        # Remove old mean\n",
    "        x_dash = x - self.mean\n",
    "        # Compute mean update\n",
    "        self.mean += x_dash / self.count\n",
    "        # Compute covariance update\n",
    "        self.square_sum += np.dot(x_dash, x_dash.T)\n",
    "    \n",
    "    @property\n",
    "    def covariance(self):\n",
    "        \"\"\"Compute covariance when requested.\"\"\"\n",
    "        return self.square_sum / self.count\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.var_processor.pb_threshold import get_rand_ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "[[127.62  ]\n",
      " [126.6561]\n",
      " [127.7728]\n",
      " [127.8828]\n",
      " [126.9163]\n",
      " [126.9174]\n",
      " [127.9779]\n",
      " [127.2481]\n",
      " [127.5458]]\n",
      "[[ 5.44840332e+03  2.73870674e+01 -8.05375009e+01 -4.12921118e+01\n",
      "   1.35894856e+02 -1.73356832e+01 -9.20126209e+00 -1.00129642e+02\n",
      "   6.91362604e+00]\n",
      " [ 2.73870674e+01  5.47821759e+03  6.49932668e+00 -4.91352540e+01\n",
      "   4.60117028e+01 -4.21126007e+00 -6.40554166e+01  1.21542875e+00\n",
      "   5.28829989e+01]\n",
      " [-8.05375009e+01  6.49932668e+00  5.51584416e+03  7.02031097e+01\n",
      "   1.42972897e+01  5.16165061e+01  7.03966528e+01  1.40461628e+01\n",
      "  -3.46599439e+01]\n",
      " [-4.12921118e+01 -4.91352540e+01  7.02031097e+01  5.50359400e+03\n",
      "   1.73218722e+01  6.02841859e+01  6.02421498e+00 -8.00309152e+01\n",
      "  -2.41932706e+00]\n",
      " [ 1.35894856e+02  4.60117028e+01  1.42972897e+01  1.73218722e+01\n",
      "   5.53078712e+03 -1.49242178e+01  5.48973093e+01 -4.85907777e+01\n",
      "   2.60099020e+01]\n",
      " [-1.73356832e+01 -4.21126007e+00  5.16165061e+01  6.02841859e+01\n",
      "  -1.49242178e+01  5.50152820e+03  1.38487274e+01  1.56215213e+01\n",
      "   6.18292543e+01]\n",
      " [-9.20126209e+00 -6.40554166e+01  7.03966528e+01  6.02421498e+00\n",
      "   5.48973093e+01  1.38487274e+01  5.46539857e+03 -1.50668013e+01\n",
      "  -7.65033079e-01]\n",
      " [-1.00129642e+02  1.21542875e+00  1.40461628e+01 -8.00309152e+01\n",
      "  -4.85907777e+01  1.56215213e+01 -1.50668013e+01  5.54194753e+03\n",
      "   3.41748114e+01]\n",
      " [ 6.91362604e+00  5.28829989e+01 -3.46599439e+01 -2.41932706e+00\n",
      "   2.60099020e+01  6.18292543e+01 -7.65033079e-01  3.41748114e+01\n",
      "   5.48716612e+03]]\n",
      "CPU times: user 575 ms, sys: 0 ns, total: 575 ms\n",
      "Wall time: 572 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "size = (3, 3)\n",
    "length = size[0]*size[1]\n",
    "\n",
    "cu = Covariance_Unit(length)\n",
    "\n",
    "for i in range(0, 10000):\n",
    "    # get a 3x3 grid of random 8-bit integers\n",
    "    rand_ints = get_rand_ints(8, size)\n",
    "    flattened = rand_ints.reshape(length, 1).astype(np.uint8)\n",
    "    cu.update(flattened)\n",
    "\n",
    "print(cu.count, cu.mean, cu.covariance, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5591.771157682662"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cu.covariance[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cu.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55917711.576826625"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cu.square_sum[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cu.covariance[0,0]/cu.covariance[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017259850427445513"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cu.covariance[0,1]/((cu.covariance[0,0]**0.5)*(cu.covariance[1,1]**0.5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017259850427445513"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cu.square_sum[0,1]/((cu.square_sum[0,0]**0.5)*(cu.square_sum[1,1]**0.5)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions and points:\n",
    "* Can we store the mean as an uint8?\n",
    "    * Not as when we divide by count > 256 we naturally get a not uint8 number\n",
    "* Can we scale to have unit variance?\n",
    "    * This is Pearson's correlation - for entry jk we need to divide by the covariance value for sqrt(c\\_jj\\*c\\_kk)\n",
    "    * Based on here - http://users.stat.umn.edu/~helwig/notes/datamat-Notes.pdf, we just scale using a diagonal matrix\n",
    "    * We divide x_dash by a vector containing the sqrt of the difference squared\n",
    "    * Is the divider the skew? https://www.johndcook.com/blog/skewness_kurtosis/\n",
    "    * Do we also track the SD and divide? Scaling factor is average of squares\n",
    "    * Scaling factor is the diagonal entries of the covariance matrix\n",
    "    * Do we just divide by the absolute value of x_dash?\n",
    "\n",
    "We normalise at each iteration (or each batch)\n",
    "\n",
    "We could do we scaling at each iteration. If we consider 0 to 1 to be scaled to the bit representation (so for 8-bit we have 0 to 255 etc).\n",
    "\n",
    "But careful because once we start subtracting we will get unsigned integers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can normalise by dividing by the absolute but we need to do a trick for 0 values (or add a small factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1. -1.  1.  1.  0.]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([-1, -2, 4, 5, 0])\n",
    "norm = np.round(a / (np.abs(a) + 0.0001))\n",
    "print(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version \n",
    "\n",
    "class Correlation_Unit(Covariance_Unit):\n",
    "    \"\"\"A model to compute correlation online.\"\"\"\n",
    "\n",
    "    def update(self, x):\n",
    "        \"\"\"Add a data point x.\n",
    "        \n",
    "        x is a 1D numpy array of length 'size'.\n",
    "        \"\"\"\n",
    "        self.count += 1\n",
    "        # Remove old mean\n",
    "        x_dash = x - self.mean\n",
    "        # Compute mean update\n",
    "        self.mean += np.round(x_dash / self.count)\n",
    "        # Normalise x_dash\n",
    "        x_dash_norm = np.round(x_dash / (np.abs(x_dash) + 0.0001))\n",
    "        # Compute covariance update\n",
    "        self.square_sum += np.dot(x_dash_norm, x_dash_norm.T)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "[[127.]\n",
      " [131.]\n",
      " [133.]\n",
      " [122.]\n",
      " [123.]\n",
      " [133.]\n",
      " [133.]\n",
      " [130.]\n",
      " [126.]]\n",
      "[[ 9.958e-01 -2.600e-03  2.060e-02  1.390e-02  2.410e-02 -1.950e-02\n",
      "   1.130e-02 -4.000e-04  1.180e-02]\n",
      " [-2.600e-03  9.966e-01  6.700e-03  1.390e-02  1.430e-02 -1.610e-02\n",
      "   9.800e-03 -1.360e-02 -2.200e-03]\n",
      " [ 2.060e-02  6.700e-03  9.945e-01 -1.460e-02  1.480e-02  1.580e-02\n",
      "  -7.800e-03  1.450e-02 -9.500e-03]\n",
      " [ 1.390e-02  1.390e-02 -1.460e-02  9.959e-01  2.600e-03  3.800e-03\n",
      "  -1.300e-02 -1.450e-02 -4.300e-03]\n",
      " [ 2.410e-02  1.430e-02  1.480e-02  2.600e-03  9.971e-01 -1.800e-03\n",
      "   5.400e-03  4.900e-03  5.900e-03]\n",
      " [-1.950e-02 -1.610e-02  1.580e-02  3.800e-03 -1.800e-03  9.965e-01\n",
      "  -7.700e-03  1.990e-02  5.900e-03]\n",
      " [ 1.130e-02  9.800e-03 -7.800e-03 -1.300e-02  5.400e-03 -7.700e-03\n",
      "   9.951e-01  3.300e-03  8.000e-04]\n",
      " [-4.000e-04 -1.360e-02  1.450e-02 -1.450e-02  4.900e-03  1.990e-02\n",
      "   3.300e-03  9.956e-01  6.100e-03]\n",
      " [ 1.180e-02 -2.200e-03 -9.500e-03 -4.300e-03  5.900e-03  5.900e-03\n",
      "   8.000e-04  6.100e-03  9.970e-01]]\n",
      "CPU times: user 723 ms, sys: 0 ns, total: 723 ms\n",
      "Wall time: 720 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "size = (3, 3)\n",
    "length = size[0]*size[1]\n",
    "\n",
    "cu = Correlation_Unit(length)\n",
    "\n",
    "for i in range(0, 10000):\n",
    "    # get a 3x3 grid of random 8-bit integers\n",
    "    rand_ints = get_rand_ints(8, size)\n",
    "    flattened = rand_ints.reshape(length, 1).astype(np.uint8)\n",
    "    cu.update(flattened)\n",
    "\n",
    "print(cu.count, cu.mean, cu.covariance, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9961"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cu.covariance[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually faster to normalise at the end.\n",
    "\n",
    "But we need to be careful of overflow over lots of samples as the sume of squares will get very big for integer values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Values and Covariance\n",
    "\n",
    "Actually, let's see what happens when we apply a binary threshold to the input data and then take the covariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.var_processor.pb_threshold import pb_threshold\n",
    "\n",
    "def pb_threshold(input_values):\n",
    "    \"\"\"Apply a probablistic binary threshold to the input_values.\"\"\"\n",
    "    input_size = input_values.shape\n",
    "    data_type = input_values.dtype\n",
    "    bit_size = data_type.itemsize*8\n",
    "    rand_ints = get_rand_ints(bit_size, input_size)\n",
    "    binary_values = np.where(input_values > rand_ints, 1, 0)\n",
    "    return binary_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "[[0.4958]\n",
      " [0.5066]\n",
      " [0.5015]\n",
      " [0.4992]\n",
      " [0.497 ]\n",
      " [0.5033]\n",
      " [0.4952]\n",
      " [0.5028]\n",
      " [0.4999]]\n",
      "[[ 2.50186820e-01  8.36299275e-04 -1.13808804e-03 -1.12136938e-03\n",
      "  -3.71343386e-03  2.98742430e-03  1.08950235e-03  2.31453833e-03\n",
      "   3.76951093e-03]\n",
      " [ 8.36299275e-04  2.50279490e-01 -2.52116950e-04 -8.22433063e-04\n",
      "  -2.68356350e-03 -3.48541760e-03 -8.99611734e-04 -6.36173920e-04\n",
      "  -1.35102301e-03]\n",
      " [-1.13808804e-03 -2.52116950e-04  2.50258582e-01 -7.25005193e-05\n",
      "   2.65364055e-03 -2.38452726e-04 -1.00275129e-03  4.87834905e-05\n",
      "   9.16106900e-04]\n",
      " [-1.12136938e-03 -8.22433063e-04 -7.25005193e-05  2.50239437e-01\n",
      "   1.29975085e-03  4.72407901e-03  2.91564132e-03  5.22789024e-03\n",
      "  -3.49098927e-03]\n",
      " [-3.71343386e-03 -2.68356350e-03  2.65364055e-03  1.29975085e-03\n",
      "   2.50207450e-01 -3.54917152e-03  8.13469168e-05 -2.45221585e-03\n",
      "   4.54400126e-04]\n",
      " [ 2.98742430e-03 -3.48541760e-03 -2.38452726e-04  4.72407901e-03\n",
      "  -3.54917152e-03  2.50251944e-01 -2.48974656e-03  2.13059917e-03\n",
      "   2.52416170e-03]\n",
      " [ 1.08950235e-03 -8.99611734e-04 -1.00275129e-03  2.91564132e-03\n",
      "   8.13469168e-05 -2.48974656e-03  2.50340522e-01 -1.60230643e-03\n",
      "   2.25023354e-03]\n",
      " [ 2.31453833e-03 -6.36173920e-04  4.87834905e-05  5.22789024e-03\n",
      "  -2.45221585e-03  2.13059917e-03 -1.60230643e-03  2.50218519e-01\n",
      "   7.81997316e-04]\n",
      " [ 3.76951093e-03 -1.35102301e-03  9.16106900e-04 -3.49098927e-03\n",
      "   4.54400126e-04  2.52416170e-03  2.25023354e-03  7.81997316e-04\n",
      "   2.50326135e-01]]\n",
      "CPU times: user 981 ms, sys: 0 ns, total: 981 ms\n",
      "Wall time: 978 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "size = (3, 3)\n",
    "length = size[0]*size[1]\n",
    "\n",
    "cu = Covariance_Unit(length)\n",
    "\n",
    "for i in range(0, 10000):\n",
    "    # get a 3x3 grid of random 8-bit integers\n",
    "    rand_ints = get_rand_ints(8, size).astype(np.uint8)\n",
    "    thresholded = pb_threshold(rand_ints)\n",
    "    flattened = thresholded.reshape(length, 1)\n",
    "    cu.update(flattened)\n",
    "\n",
    "print(cu.count, cu.mean, cu.covariance, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2502339448910254"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cu.covariance[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2502.339448910254"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cu.square_sum[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using binary values kinda normalises our covariance anyway without a need for additional scaling.\n",
    "\n",
    "Again it would be good to get rid of the count value - just have normalised on each round. Info on normalsiing here - https://stackoverflow.com/questions/2850743/numpy-how-to-quickly-normalize-many-vectors - fast normalisation is given by np.sqrt(np.einsum('...i,...i', vectors, vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Correlation_Unit(Covariance_Unit):\n",
    "    \"\"\"A model to compute correlation online.\"\"\"\n",
    "\n",
    "    def update(self, x):\n",
    "        \"\"\"Add a data point x.\n",
    "        \n",
    "        x is a 1D numpy array of length 'size'.\n",
    "        \"\"\"\n",
    "        self.count += 1\n",
    "        # Remove old mean\n",
    "        x_dash = x - self.mean\n",
    "        # Compute mean update\n",
    "        self.mean += x_dash / self.count\n",
    "        # Normalise x_dash\n",
    "        x_dash_norm = np.round(x_dash / (np.abs(x_dash) + 0.0001))\n",
    "        # Compute covariance update\n",
    "        self.square_sum += np.dot(x_dash_norm, x_dash_norm.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "[[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[ 0.4931 -0.2382 -0.2466 -0.2454  0.2453  0.2411  0.2507 -0.2465 -0.2473]\n",
      " [-0.2382  0.4935  0.2495  0.2499 -0.2499 -0.2477 -0.253   0.2429  0.2482]\n",
      " [-0.2466  0.2495  0.5002  0.2492 -0.2491 -0.2521 -0.2532  0.2539  0.2549]\n",
      " [-0.2454  0.2499  0.2492  0.499  -0.2552 -0.2483 -0.2516  0.2528  0.2496]\n",
      " [ 0.2453 -0.2499 -0.2491 -0.2552  0.5029  0.254   0.2519 -0.2505 -0.249 ]\n",
      " [ 0.2411 -0.2477 -0.2521 -0.2483  0.254   0.4981  0.2497 -0.2436 -0.2484]\n",
      " [ 0.2507 -0.253  -0.2532 -0.2516  0.2519  0.2497  0.5068 -0.2553 -0.2517]\n",
      " [-0.2465  0.2429  0.2539  0.2528 -0.2505 -0.2436 -0.2553  0.5027  0.2505]\n",
      " [-0.2473  0.2482  0.2549  0.2496 -0.249  -0.2484 -0.2517  0.2505  0.5009]]\n",
      "CPU times: user 1.12 s, sys: 0 ns, total: 1.12 s\n",
      "Wall time: 1.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "size = (3, 3)\n",
    "length = size[0]*size[1]\n",
    "\n",
    "cu = Correlation_Unit(length)\n",
    "\n",
    "for i in range(0, 10000):\n",
    "    # get a 3x3 grid of random 8-bit integers\n",
    "    rand_ints = get_rand_ints(8, size).astype(np.uint8)\n",
    "    thresholded = pb_threshold(rand_ints)\n",
    "    flattened = thresholded.reshape(length, 1)\n",
    "    cu.update(flattened)\n",
    "\n",
    "print(cu.count, cu.mean, cu.covariance, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need to normalise x_dash because it will already be small.\n",
    "\n",
    "We do need to normalise the square_sum..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaled_CU:\n",
    "    \"\"\"A model to compute s scaled update online with no count.\"\"\"\n",
    "\n",
    "    def __init__(self, size, update_factor=0.01):\n",
    "        \"\"\"Initialise.\n",
    "        \n",
    "        size is an integer setting the 1D size of an input;\n",
    "        update_factor is a factor 0 > f <= 1.\n",
    "        \n",
    "        The update factor should be ~ batch size.\"\"\"\n",
    "        self.size = size\n",
    "        self.uf = update_factor\n",
    "        self.mean = np.zeros(shape=(size, 1))\n",
    "        self.square_sum = np.zeros(shape=(size, size))\n",
    "        self.reset_count = 0\n",
    "\n",
    "    def update(self, x):\n",
    "        \"\"\"Add a data point x.\n",
    "        \n",
    "        x is a 1D numpy array of length 'size'.\n",
    "        \"\"\"\n",
    "        # Remove old mean\n",
    "        x_dash = x - self.mean\n",
    "        # Compute mean update\n",
    "        self.mean += self.uf*(x_dash)\n",
    "        # Compute square matrix scale factor based on SD - but this division may slow down\n",
    "        # Extra factor to avoid division by 0\n",
    "        mask = x_dash != 0\n",
    "        x_dash[mask] = x_dash[mask] * np.abs(x_dash[mask])**-1\n",
    "        # Compute covariance update\n",
    "        self.square_sum += np.dot(x_dash, x_dash.T)\n",
    "        \n",
    "        # Now we need to normalise again the square sum\n",
    "        # We can do this every 1/update_factor samples\n",
    "        self.reset_count += 1\n",
    "        correction_factor = self.uf**-1\n",
    "        if self.reset_count > correction_factor:\n",
    "            self.reset_count = 0\n",
    "            self.square_sum = self.square_sum / correction_factor\n",
    "    \n",
    "    @property\n",
    "    def correlation(self):\n",
    "        \"\"\"Compute covariance when requested.\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearly there - but because we've scaled our square_sum to have max sum of 1, as we add consecutive, we end up with count values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.46948023]\n",
      " [0.41075422]\n",
      " [0.57070639]\n",
      " [0.43224553]\n",
      " [0.46227332]\n",
      " [0.49466475]\n",
      " [0.55275045]\n",
      " [0.47899044]\n",
      " [0.45956529]]\n",
      "[[ 2.02020202  1.02890303 -1.11191677  1.11210305 -1.10949301 -0.95088295\n",
      "   1.17010893 -1.09288509 -0.98950697]\n",
      " [ 1.02890303  2.02020202 -1.20949895  1.08849299 -0.96949915 -0.96849301\n",
      "   0.90970695 -0.98970691 -0.93151307]\n",
      " [-1.11191677 -1.20949895  2.02020202 -1.21068689  1.16890897  0.92909911\n",
      "  -1.11109721  0.91149709  1.09091089]\n",
      " [ 1.11210305  1.08849299 -1.21068689  2.02020202 -1.08869889 -0.97130519\n",
      "   1.07089493 -0.99089897 -1.09191305]\n",
      " [-1.10949301 -0.96949915  1.16890897 -1.08869889  2.02020202  0.93069887\n",
      "  -1.14868085  0.86908901  1.05010297]\n",
      " [-0.95088295 -0.96849301  0.92909911 -0.97130519  0.93069887  2.02020202\n",
      "  -0.94891107  1.03129487  1.12948515]\n",
      " [ 1.17010893  0.90970695 -1.11109721  1.07089493 -1.14868085 -0.94891107\n",
      "   2.02020202 -0.93050101 -0.86907905]\n",
      " [-1.09288509 -0.98970691  0.91149709 -0.99089897  0.86908901  1.03129487\n",
      "  -0.93050101  2.02020202  1.07070293]\n",
      " [-0.98950697 -0.93151307  1.09091089 -1.09191305  1.05010297  1.12948515\n",
      "  -0.86907905  1.07070293  2.02020202]]\n",
      "CPU times: user 1.1 s, sys: 10.7 ms, total: 1.11 s\n",
      "Wall time: 1.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "size = (3, 3)\n",
    "length = size[0]*size[1]\n",
    "\n",
    "cu = Scaled_CU(length)\n",
    "\n",
    "for i in range(0, 10000):\n",
    "    # get a 3x3 grid of random 8-bit integers\n",
    "    rand_ints = get_rand_ints(8, size).astype(np.uint8)\n",
    "    thresholded = pb_threshold(rand_ints)\n",
    "    flattened = thresholded.reshape(length, 1)\n",
    "    cu.update(flattened)\n",
    "\n",
    "print(cu.mean, cu.square_sum, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.00000000001425"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cu.square_sum[-1, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the values above are too high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaled_CU2:\n",
    "    \"\"\"A model to compute s scaled update online with no count.\"\"\"\n",
    "\n",
    "    def __init__(self, size):\n",
    "        \"\"\"Initialise.\n",
    "        \n",
    "        Args:\n",
    "            size: integer setting the 1D size of an input.\n",
    "        \"\"\"\n",
    "        self.size = size\n",
    "        self.count = 0\n",
    "        self.x_sum = np.zeros(shape=(size, 1))\n",
    "        self.square_sum = np.zeros(shape=(size, size))\n",
    "\n",
    "    def update(self, x):\n",
    "        \"\"\"Add a data point x.\n",
    "        \n",
    "        x is a 1D numpy array of length 'size'.\n",
    "        \"\"\"\n",
    "        self.count += 1\n",
    "        self.x_sum += x\n",
    "        x_dash = self.x_sum - self.count*x\n",
    "        scale_factor = self.count*(self.count+1)\n",
    "        self.square_sum += (scale_factor**-1)*np.dot(x_dash, x_dash.T)\n",
    "    \n",
    "    @property\n",
    "    def mean(self):\n",
    "        \"\"\"Compute mean when requested.\"\"\"\n",
    "        return self.x_sum / self.count\n",
    "    \n",
    "    @property\n",
    "    def correlation(self):\n",
    "        \"\"\"Compute covariance when requested.\"\"\"\n",
    "        return self.square_sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4946]\n",
      " [0.4944]\n",
      " [0.5032]\n",
      " [0.5061]\n",
      " [0.5015]\n",
      " [0.4909]\n",
      " [0.5098]\n",
      " [0.4986]\n",
      " [0.4931]]\n",
      "[[ 2.49574795e-01 -3.84130589e-03  4.60581043e-03 -2.06704296e-03\n",
      "  -2.35228749e-03  2.21821548e-03  2.53346294e-03  1.47247746e-03\n",
      "  -5.27575357e-04]\n",
      " [-3.84130589e-03  2.49542091e-01 -4.37181132e-03 -1.19821839e-03\n",
      "   7.71378418e-04 -3.13733726e-03  9.30436269e-04 -1.87617167e-03\n",
      "  -6.54775579e-04]\n",
      " [ 4.60581043e-03 -4.37181132e-03  2.49573312e-01 -5.32032097e-04\n",
      "   7.04100103e-03  1.45058157e-03 -2.41259530e-04  1.32179210e-03\n",
      "   1.38695247e-04]\n",
      " [-2.06704296e-03 -1.19821839e-03 -5.32032097e-04  2.49546800e-01\n",
      "  -2.82985470e-03  2.89042243e-03 -3.81524404e-03 -4.96131295e-03\n",
      "  -1.16338861e-03]\n",
      " [-2.35228749e-03  7.71378418e-04  7.04100103e-03 -2.82985470e-03\n",
      "   2.49596163e-01 -1.51390050e-03 -2.66830147e-03 -6.40916506e-03\n",
      "   6.84623922e-04]\n",
      " [ 2.21821548e-03 -3.13733726e-03  1.45058157e-03  2.89042243e-03\n",
      "  -1.51390050e-03  2.49499076e-01  6.73865266e-03  9.83409233e-04\n",
      "   2.00258587e-03]\n",
      " [ 2.53346294e-03  9.30436269e-04 -2.41259530e-04 -3.81524404e-03\n",
      "  -2.66830147e-03  6.73865266e-03  2.49487616e-01  6.38113332e-04\n",
      "   3.68048020e-03]\n",
      " [ 1.47247746e-03 -1.87617167e-03  1.32179210e-03 -4.96131295e-03\n",
      "  -6.40916506e-03  9.83409233e-04  6.38113332e-04  2.49580758e-01\n",
      "  -3.40432478e-04]\n",
      " [-5.27575357e-04 -6.54775579e-04  1.38695247e-04 -1.16338861e-03\n",
      "   6.84623922e-04  2.00258587e-03  3.68048020e-03 -3.40432478e-04\n",
      "   2.49532804e-01]]\n",
      "CPU times: user 1.03 s, sys: 3.56 ms, total: 1.03 s\n",
      "Wall time: 1.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "size = (3, 3)\n",
    "length = size[0]*size[1]\n",
    "\n",
    "cu = Scaled_CU2(length)\n",
    "\n",
    "for i in range(0, 10000):\n",
    "    # get a 3x3 grid of random 8-bit integers\n",
    "    rand_ints = get_rand_ints(8, size).astype(np.uint8)\n",
    "    thresholded = pb_threshold(rand_ints)\n",
    "    flattened = thresholded.reshape(length, 1)\n",
    "    cu.update(flattened)\n",
    "\n",
    "print(cu.mean, cu.correlation, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5013    ]\n",
      " [0.49573333]\n",
      " [0.49636667]\n",
      " [0.4964    ]\n",
      " [0.49556667]\n",
      " [0.50046667]\n",
      " [0.504     ]\n",
      " [0.50086667]\n",
      " [0.50136667]]\n",
      "[[ 2.49857525e-01  1.62767234e-03 -2.02911061e-03  1.33547234e-03\n",
      "   7.73800037e-04 -5.80474215e-04  4.79195511e-04  1.14245432e-04\n",
      "   5.32403555e-04]\n",
      " [ 1.62767234e-03  2.49832204e-01 -1.61735733e-03  5.18056408e-04\n",
      "   5.23566788e-04 -1.23963515e-03 -3.16587579e-03 -6.28717574e-04\n",
      "   3.35572578e-03]\n",
      " [-2.02911061e-03 -1.61735733e-03  2.49827254e-01  1.42226402e-03\n",
      "   2.49880375e-04 -5.46248548e-04  1.59746203e-03  7.34813152e-04\n",
      "   4.46889823e-04]\n",
      " [ 1.33547234e-03  5.18056408e-04  1.42226402e-03  2.49827757e-01\n",
      "  -1.00494204e-03 -2.91974910e-03  1.57329005e-03  8.03026623e-04\n",
      "   2.80379646e-03]\n",
      " [ 7.73800037e-04  5.23566788e-04  2.49880375e-04 -1.00494204e-03\n",
      "   2.49823633e-01 -6.34483193e-04  5.60258300e-04  2.79203076e-03\n",
      "   5.45643174e-04]\n",
      " [-5.80474215e-04 -1.23963515e-03 -5.46248548e-04 -2.91974910e-03\n",
      "  -6.34483193e-04  2.49846219e-01  7.01011331e-04  2.49363121e-03\n",
      "   2.30903485e-03]\n",
      " [ 4.79195511e-04 -3.16587579e-03  1.59746203e-03  1.57329005e-03\n",
      "   5.60258300e-04  7.01011331e-04  2.49826000e-01 -4.54765168e-04\n",
      "  -1.09149636e-03]\n",
      " [ 1.14245432e-04 -6.28717574e-04  7.34813152e-04  8.03026623e-04\n",
      "   2.79203076e-03  2.49363121e-03 -4.54765168e-04  2.49840278e-01\n",
      "  -1.28644350e-03]\n",
      " [ 5.32403555e-04  3.35572578e-03  4.46889823e-04  2.80379646e-03\n",
      "   5.45643174e-04  2.30903485e-03 -1.09149636e-03 -1.28644350e-03\n",
      "   2.49837311e-01]]\n",
      "CPU times: user 3.05 s, sys: 6.64 ms, total: 3.06 s\n",
      "Wall time: 3.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "size = (3, 3)\n",
    "length = size[0]*size[1]\n",
    "\n",
    "cu = Scaled_CU2(length)\n",
    "\n",
    "for i in range(0, 30000):\n",
    "    # get a 3x3 grid of random 8-bit integers\n",
    "    rand_ints = get_rand_ints(8, size).astype(np.uint8)\n",
    "    thresholded = pb_threshold(rand_ints)\n",
    "    flattened = thresholded.reshape(length, 1)\n",
    "    cu.update(flattened)\n",
    "\n",
    "print(cu.mean, cu.correlation, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The thresholding slows us up more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could we combine an online and batch update to allow continuous operation?\n",
    "\n",
    "E.g. reset every n samples and sum as two n batches?\n",
    "\n",
    "We have:\n",
    "\n",
    "```\n",
    "XX_AB = XX_A + XX_B + (n_A*n_B)/(n_AB) * (x_bar_A - x_bar_B)(x_bar_A - x_bar_B)\n",
    "```\n",
    "\n",
    "Or add the covariances then add a factor based on the difference of the means, where the new meanP:\n",
    "```\n",
    "x_bar_X = (n_A*x_bar_A + n_b*x_bar_B) / (n_A + n_B)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Continuous_CU:\n",
    "    \"\"\"A model to compute a continous mean and covariance.\"\"\"\n",
    "\n",
    "    def __init__(self, size, batch_size=1000):\n",
    "        \"\"\"Initialise.\n",
    "        \n",
    "        size is an integer setting the 1D size of an input.\"\"\"\n",
    "        self.size = size\n",
    "        self.count = 0\n",
    "        self.x_sum = np.zeros(shape=(size, 1))\n",
    "        self.square_sum = np.zeros(shape=(size, size))\n",
    "        # Additional variables to store running mean + covar\n",
    "        self.mean = np.zeros(shape=(size, 1))\n",
    "        self.covariance = np.zeros(shape=(size, size))\n",
    "        # Running count for batch\n",
    "        self.batch_count = 0\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def update(self, x):\n",
    "        \"\"\"Add a data point x.\n",
    "        \n",
    "        x is a 1D numpy array of length 'size'.\n",
    "        \"\"\"\n",
    "        self.count += 1\n",
    "        self.x_sum += x\n",
    "        x_dash = self.x_sum - self.count*x\n",
    "        scale_factor = self.count*(self.count+1)\n",
    "        self.square_sum += (scale_factor**-1)*np.dot(x_dash, x_dash.T)\n",
    "        \n",
    "    def update_mean(self):\n",
    "        \"\"\"Update mean after a batch is processed.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def update_covariance(self):\n",
    "        \"\"\"Update covariance after a batch is processed.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @property\n",
    "    def covariance(self):\n",
    "        \"\"\"Compute covariance when requested.\"\"\"\n",
    "        return self.square_sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing\n",
    "\n",
    "I think the getting of random integers and the thresholding is reasonably slow. Let's have a look at timing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         63 function calls in 0.000 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.000    0.000 <string>:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 <string>:12(__new__)\n",
      "        1    0.000    0.000    0.000    0.000 pb_threshold.py:6(get_rand_ints)\n",
      "        2    0.000    0.000    0.000    0.000 version.py:271(__init__)\n",
      "        8    0.000    0.000    0.000    0.000 version.py:282(<genexpr>)\n",
      "        6    0.000    0.000    0.000    0.000 version.py:420(_parse_letter_version)\n",
      "        2    0.000    0.000    0.000    0.000 version.py:461(_parse_local_version)\n",
      "        2    0.000    0.000    0.000    0.000 version.py:474(_cmpkey)\n",
      "        2    0.000    0.000    0.000    0.000 version.py:48(parse)\n",
      "        3    0.000    0.000    0.000    0.000 version.py:490(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 version.py:74(__lt__)\n",
      "        1    0.000    0.000    0.000    0.000 version.py:76(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 version.py:98(_compare)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x5601bd3d3e00}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "       20    0.000    0.000    0.000    0.000 {method 'group' of '_sre.SRE_Match' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'randint' of 'mtrand.RandomState' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'search' of '_sre.SRE_Pattern' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "cProfile.run(\"\"\"rand_ints = get_rand_ints(8, size).astype(np.uint8)\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.9 µs ± 890 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "rand_ints = get_rand_ints(8, size).astype(np.uint8)\n",
    "thresholded = pb_threshold(rand_ints)\n",
    "flattened = thresholded.reshape(length, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.6 µs ± 515 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "rand_ints = get_rand_ints(8, size).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.8 µs ± 1.5 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "thresholded = pb_threshold(rand_ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
