{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll look at building a visualiser to view the VPU applied en-mass to FFT data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make our SensorSource objects iterables that return a next frame of data - https://www.programiz.com/python-programming/iterator ```__iter__``` just returns self (with any initialisation) and ```__next__``` returns self.read().\n",
    "\n",
    "Our SensorSource objects also need a way of returning the size of the frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Sensor Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "(480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "from src.sources.capture import VideoSource\n",
    "\n",
    "video = VideoSource()\n",
    "video.start()\n",
    "grabbed, frame = video.read()\n",
    "print(grabbed)\n",
    "print(frame.shape)\n",
    "\n",
    "video.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Asynchroneous capturing has already been started.\n",
      "(65536,)\n"
     ]
    }
   ],
   "source": [
    "from src.sources.capture import AudioSource\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "audio = AudioSource()\n",
    "audio.start()\n",
    "time.sleep(0.5)\n",
    "# Test read\n",
    "length1, samples1 = audio.read()\n",
    "assert length1\n",
    "assert samples1.any()\n",
    "# Check starting and getting a frame\n",
    "audio.start()\n",
    "time.sleep(0.5)\n",
    "length2, samples2 = audio.read()\n",
    "assert length2\n",
    "assert not np.array_equal(samples1, samples2)\n",
    "print(samples2.shape)\n",
    "# Test stopping\n",
    "audio.stop()\n",
    "assert not audio.started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.sources.capture import CombinedSource, SensorSource\n",
    "\n",
    "combined = CombinedSource()\n",
    "type(combined.sources) == dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined.sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(combined.sources) == dict\n",
    "assert len(combined.sources) == 0\n",
    "# Adding a source\n",
    "combined.add_source(SensorSource())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SensorSource'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(combined.sources.items())[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': array([   0,    0,    0, ..., 2927, 2824, 3613], dtype=int16), 'video': array([[[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[255, 241, 184],\n",
      "        [255, 241, 184],\n",
      "        [255, 240, 183],\n",
      "        ...,\n",
      "        [130, 124, 155],\n",
      "        [129, 123, 153],\n",
      "        [127, 122, 152]],\n",
      "\n",
      "       [[255, 240, 185],\n",
      "        [255, 240, 185],\n",
      "        [255, 240, 185],\n",
      "        ...,\n",
      "        [119, 132, 155],\n",
      "        [122, 130, 161],\n",
      "        [120, 128, 159]],\n",
      "\n",
      "       [[255, 237, 188],\n",
      "        [255, 237, 188],\n",
      "        [255, 238, 186],\n",
      "        ...,\n",
      "        [108, 135, 156],\n",
      "        [108, 131, 164],\n",
      "        [109, 133, 165]]], dtype=uint8)}\n"
     ]
    }
   ],
   "source": [
    "from src.sources.capture import AVCapture\n",
    "\n",
    "av = AVCapture()\n",
    "av.start()\n",
    "time.sleep(0.25)\n",
    "data = av.read()\n",
    "print(data)\n",
    "av.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test FFT Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sources.fft import FFTSource\n",
    "\n",
    "fft = FFTSource()\n",
    "fft.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0  33   0  42 110   0 185 162 245 172 128 223 157 206  81 130\n",
      " 200  90 179 221 167 153 163 103 159 168 159 188 242 216 130  51 134 243\n",
      "  16  45  77 250 234 199 198  58 211  99   1 212 162 232 189 156  36 209\n",
      " 139  61  82 180 114 140 212 210 103  87  94 112 106  95  48 107 200 112\n",
      "  50  76 142  71  78  43  57  72  80 116  79  52  36  32  58  50  42  21\n",
      "  18  41  35  27  34  31  17  23  23  17  20  10   9   9   8   8   7   6\n",
      "   6   6   6   6   5   5   5   5   5   5   5   5   5   4   5   4   4   4\n",
      "   4   4   4   4   4   4   4   4   4   4   4]\n"
     ]
    }
   ],
   "source": [
    "_, data = fft.read()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "fft.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Covariance Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]]\n",
      "---\n",
      "[[1.]\n",
      " [1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]]\n",
      "---\n",
      "[[4.]\n",
      " [4.]]\n",
      "[[0.66666667 0.66666667]\n",
      " [0.66666667 0.66666667]]\n",
      "[[0.33333333 0.33333333]\n",
      " [0.33333333 0.33333333]]\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from src.var_processor.covariance import CovarianceUnit\n",
    "cov_unit = CovarianceUnit(2)\n",
    "print(cov_unit.x_sum, cov_unit.square_sum, cov_unit.covariance, sep=\"\\n\", end=\"\\n---\\n\")\n",
    "assert not cov_unit.x_sum.any()\n",
    "assert not cov_unit.square_sum.any()\n",
    "# Test updating with data\n",
    "ones = np.ones(shape=(2,1))\n",
    "cov_unit.update(ones)\n",
    "assert cov_unit.count == 1\n",
    "assert np.array_equal(cov_unit.x_sum, ones)\n",
    "assert np.array_equal(cov_unit.mean, ones)\n",
    "assert not cov_unit.covariance.any()\n",
    "print(cov_unit.x_sum, cov_unit.square_sum, cov_unit.covariance, sep=\"\\n\", end=\"\\n---\\n\")\n",
    "threes = ones*3\n",
    "cov_unit.update(threes)\n",
    "assert cov_unit.count == 2\n",
    "assert np.array_equal(cov_unit.x_sum, ones+threes)\n",
    "assert cov_unit.square_sum.any()\n",
    "assert np.array_equal(cov_unit.mean, ones*2)\n",
    "assert cov_unit.covariance.any()\n",
    "print(cov_unit.x_sum, cov_unit.square_sum, cov_unit.covariance, sep=\"\\n\", end=\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.83022113],\n",
       "       [0.55743419]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.var_processor.power_iterator import PowerIterator\n",
    "\n",
    "power = PowerIterator(2)\n",
    "power.ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3826087]\n",
      " [1.       ]]\n",
      "[[0.80731506]] [[-0.33019738]\n",
      " [ 0.6209682 ]]\n",
      "[[0.80731506]] [[-0.33019738]\n",
      " [ 0.6209682 ]]\n"
     ]
    }
   ],
   "source": [
    "from src.var_processor.vpu import VPU\n",
    "\n",
    "# Intialise VPU\n",
    "vpu = VPU(2)\n",
    "# Test Iteration\n",
    "in_1 = np.random.randint(255, size=(2, 1))\n",
    "in_1 = in_1 / in_1.max()\n",
    "print(in_1)\n",
    "r, residual = vpu.iterate(in_1)\n",
    "print(r, residual)\n",
    "r, residual = vpu.iterate(in_1)\n",
    "print(r, residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.97765689]] [[0.02347528]\n",
      " [0.48736612]]\n"
     ]
    }
   ],
   "source": [
    "for _ in range(0, 100):\n",
    "    in_1 = np.random.randint(255, size=(2, 1))\n",
    "    in_1 = in_1 / in_1.max()\n",
    "    vpu.update_cov(in_1)\n",
    "r, residual = vpu.iterate(in_1)\n",
    "print(r, residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09543691, -0.06212411],\n",
       "       [-0.06212411,  0.11117773]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vpu.cu.covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99884195],\n",
       "       [-0.04811187]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vpu.pi.eigenvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09543691, -0.06212411],\n",
       "       [-0.06212411,  0.11117773]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vpu.pi.cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0983153 ]\n",
      " [-0.06740113]]\n"
     ]
    }
   ],
   "source": [
    "self = vpu.pi\n",
    "self.ev = np.matmul(np.power(self.cov, 1), self.ev)\n",
    "# Scale to have unit length (convert to integer values?)\n",
    "# self.ev = self.ev / np.linalg.norm(self.ev)\n",
    "print(self.ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09543691, -0.06212411],\n",
       "       [-0.06212411,  0.11117773]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.power(self.cov, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0983153 ],\n",
       "       [-0.06740113]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self.ev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah this is it - if self.ev becomes nan it stays as nan. Need a check to prevent this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]] [[0.]\n",
      " [0.]]\n",
      "[[0.23332932 0.02195817]\n",
      " [0.02195817 0.2293767 ]]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-969616e1893a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvpu2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mvpu2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mcause\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mvpu2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Intialise VPU\n",
    "vpu2 = VPU(2)\n",
    "# Test Iteration\n",
    "for _ in range(0, 100):\n",
    "    data_in = np.random.randint(2, size=(2, 1))\n",
    "    cause, residual = vpu2.iterate(data_in)\n",
    "print(cause, residual)\n",
    "print(vpu2.cu.covariance)\n",
    "assert vpu2.cu.covariance.any()\n",
    "assert cause.any()\n",
    "assert residual.any()\n",
    "vpu2.reset()\n",
    "# assert not vpu2.cu.covariance.any()\n",
    "print(vpu2.cu.covariance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BufferVPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.var_processor.vpu import BufferVPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vpu = BufferVPU(2, 4)\n",
    "assert vpu.buffer.shape == (2, 4)\n",
    "assert vpu.cu.covariance.shape == (8, 8)\n",
    "assert vpu.pi.ev.shape == (8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] (8, 1)\n"
     ]
    }
   ],
   "source": [
    "reshaped = vpu.buffer.reshape(-1, 1)\n",
    "print(reshaped, reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Iteration\n",
    "for _ in range(0, 100):\n",
    "    data_in = np.random.randint(2, size=(2, 1))\n",
    "    cause, residual = vpu.iterate(data_in)\n",
    "old_cov = vpu.cu.covariance\n",
    "assert old_cov.any()\n",
    "vpu.reset()\n",
    "new_cov = vpu.cu.covariance\n",
    "assert not np.array_equal(old_cov, new_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensor Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input into each VPU is a vector of N. Whatever the stage.\n",
    "\n",
    "Stage.\n",
    "* Internal variables (for init)\n",
    "    * vec_len - vector length (N)\n",
    "* Methods\n",
    "    * __init__ - initialise a set of VPUs for one time stage. \n",
    "        * Input\n",
    "            * stage_len - number of stages (k)\n",
    "            * vec_len - vector length (N)\n",
    "    * forward - input data and update VPUs.\n",
    "        * Input:\n",
    "            * stage_in - array of input data for stage.\n",
    "        * Return:  \n",
    "            * updated Rs and residuals for the stage as numpy array\n",
    "    * get_cause - get the Rs from all individual VPUs. In binary form or float form?\n",
    "        * Return:\n",
    "            * causes - numpy array of Rs\n",
    "\n",
    "We might actually want a \"stage\" object. generate_stage and process_stage are \"stage\" methods.\n",
    "\n",
    "Time stages = logN(sensor_resolution)\n",
    "\n",
    "We need a common way of getting the sensor_resolution. First time stage has sensor_resolution/N VPUs.\n",
    "\n",
    "See:\n",
    "* https://github.com/benhoyle/predictive_coding/blob/master/2019-10-28%20SpaceTime%20Grid%20object%20development.ipynb\n",
    "* https://github.com/benhoyle/predictive_coding/blob/master/Time%20Filtering.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is very similar to our \"layer\" in the predictive_coding brain code. But we are flattening everything to 1D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.var_processor.vpu import VPU\n",
    "\n",
    "class TimeStage:\n",
    "    \"\"\"Object to represent a time stage of processing.\"\"\"\n",
    "    \n",
    "    def __init__(self, vec_len, stage_len):\n",
    "        \"\"\"Initialise stage.\n",
    "        \n",
    "        Arg:\n",
    "            vec_len - length of each 1D vector processed by the VPUs.\n",
    "            stage_len - integer indicating number of VPUs.\n",
    "        \"\"\"\n",
    "        self.vec_len = vec_len\n",
    "        self.stage_len = stage_len\n",
    "        self.size = self.vec_len*self.stage_len\n",
    "        self.vpus = [VPU(vec_len) for _ in range(0, stage_len)]\n",
    "        # Create a blank array for the causes\n",
    "        self.causes = np.zeros(shape=(stage_len, 1))\n",
    "        # Create a blank array for the residuals\n",
    "        self.residuals = np.zeros(shape=(self.size, 1))\n",
    "        \n",
    "    def forward(self, stage_in):\n",
    "        \"\"\"Pass data to the stage for processing.\n",
    "        \n",
    "        Arg:\n",
    "            stage_in - 1D numpy array with data to process.\n",
    "        \"\"\"\n",
    "        # Create blank array to hold / pad data\n",
    "        \n",
    "        input_array = np.zeros(shape=(self.size, 1))\n",
    "        # Check data is of right size\n",
    "        if stage_in.shape[0] > self.size:\n",
    "            # Crop input\n",
    "            input_array = stage_in[:self.size]\n",
    "        elif stage_in.shape[0] < self.size:\n",
    "            input_array[:self.size] = stage_in\n",
    "        else:\n",
    "            input_array = stage_in\n",
    "        # Iterate through VPUs, passing data in\n",
    "        # Create a blank array for the causes\n",
    "        causes = np.zeros\n",
    "        for i, vpu in enumerate(self.vpus):\n",
    "            start = i*self.vec_len\n",
    "            end = (i+1)*self.vec_len\n",
    "            r, residual = vpu.iterate(input_array[start:end])\n",
    "            self.causes[i] = r\n",
    "            self.residuals[start:end] = residual\n",
    "        \n",
    "    def get_causes(self):\n",
    "        \"\"\"Return output of VPUs as array.\"\"\"\n",
    "        return self.causes\n",
    "    \n",
    "    def get_residuals(self):\n",
    "        \"\"\"Return residual output as array.\"\"\"\n",
    "        return self.residuals\n",
    "    \n",
    "    def __repr__(self):\n",
    "        \"\"\"Print layer information.\"\"\"\n",
    "        string = f\"There are {self.stage_len} units \\n\"\n",
    "        string += f\"with dimensionality {self.vec_len}x1\"\n",
    "        return string\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10 units \n",
      "with dimensionality 3x1\n"
     ]
    }
   ],
   "source": [
    "stages = TimeStage(3, 10)\n",
    "assert len(stages.vpus) == 10\n",
    "assert not stages.causes.any()\n",
    "assert not stages.residuals.any()\n",
    "print(stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "data_in = np.random.randint(2, size=(stages.size, 1))\n",
    "print(data_in.T)\n",
    "\n",
    "stages.forward(data_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7781574 ],\n",
       "       [0.4959966 ],\n",
       "       [0.40622868],\n",
       "       [0.73711774],\n",
       "       [1.70856429],\n",
       "       [1.09356688],\n",
       "       [0.84952028],\n",
       "       [0.56916066],\n",
       "       [1.18635544],\n",
       "       [0.        ]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stages.causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49539255],\n",
       "       [ 0.89907851],\n",
       "       [-0.58370807],\n",
       "       [ 0.87994584],\n",
       "       [ 0.87404153],\n",
       "       [-0.46447184],\n",
       "       [-0.36740689],\n",
       "       [ 0.83497826],\n",
       "       [-0.0529315 ],\n",
       "       [ 0.70340475],\n",
       "       [-0.62808406],\n",
       "       [ 0.75325269],\n",
       "       [-0.00577201],\n",
       "       [-0.15295815],\n",
       "       [ 0.23953824],\n",
       "       [ 0.09764776],\n",
       "       [-0.54358569],\n",
       "       [ 0.70646373],\n",
       "       [-0.21090329],\n",
       "       [ 0.2783153 ],\n",
       "       [-0.39544367],\n",
       "       [-0.03409935],\n",
       "       [ 0.67605614],\n",
       "       [-0.4667349 ],\n",
       "       [ 0.1863242 ],\n",
       "       [-0.62675028],\n",
       "       [ 0.40623658],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stages.residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a method to \"bed in\" the covariance - we need to input data for a certain number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"9\" in stages.__repr__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SensorSource needs a get_data_size() method. Or we could add this to the Sensor methods.\n",
    "\n",
    "Class object. \n",
    "* Internal variables (for init)\n",
    "    * sensor_source - sensor that is providing the data.\n",
    "    * vec_len - vector length (N)\n",
    "    * time_len - length of time buffering (M)\n",
    "* Methods\n",
    "    * build_stages - build and initialise the time stages.\n",
    "    * generate_stage - create a new time stage.\n",
    "    * get_data_size - determine the 1D size of the data from the sensor source.\n",
    "        * Return:\n",
    "            * size - integer indicating the 1D size.\n",
    "    * get_frame - get a frame of data from the sensor. Add thresholding here?\n",
    "        * Return:\n",
    "            * frame\n",
    "    * iterate - high-level loop for all stages.\n",
    "        * Return:\n",
    "            * Array of Rs for visualisation?\n",
    "    * cause_as_image - return the causes for each stage as an image - upscales stages with lower numbers of causes.\n",
    "    * cause_pyramid - return causes as list of numpy arrays.\n",
    "    * residual_pyramid - return residuals as list of numpy arrays.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the set of stages:\n",
    "* Compute number of stages.\n",
    "* Loop over number of stages.\n",
    "    * Determine stage_len.\n",
    "    * Generate stage - add returned stage to list.\n",
    "* Return list of stages.\n",
    "\n",
    "\n",
    "The number of stages = math.log(SR, vec_len) - 1. If SR is a power, the log is an integer value, else it is a decimal and we want to take the floor of the value and crop the data. Like previous methods we can crop right, left or centre. Or we could resize instead of cropping (more intensive but easier to implement).\n",
    "\n",
    "```#simple image scaling to (nR x nC) size\n",
    "def scale(im, nR, nC):\n",
    "  nR0 = len(im)     # source number of rows \n",
    "  nC0 = len(im[0])  # source number of columns \n",
    "  return [[ im[int(nR0 * r / nR)][int(nC0 * c / nC)]  \n",
    "             for c in range(nC)] for r in range(nR)]\n",
    "```\n",
    "Or https://docs.scipy.org/doc/numpy/reference/generated/numpy.interp.html .\n",
    "\n",
    "We can shrink to the nearest power? This at least doesn't increase dimensionality at the cost of lossing detail. But apparently we can interpolate downwards...\n",
    "For a 1D case:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0, 10-1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 2.25, 4.5 , 6.75, 9.  ])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0, 10-1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(array, elem_num):\n",
    "    \"\"\"Scale array.\n",
    "    \n",
    "    Arg:\n",
    "        elem_num - integer number of new elements in array.\n",
    "    \"\"\"\n",
    "    old_length = array.shape[0]\n",
    "    x = np.linspace(0, old_length-1, elem_num)\n",
    "    xp = np.linspace(0, old_length-1, old_length)\n",
    "    return np.interp(x, xp, array.flatten()).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  ]\n",
      " [2.25]\n",
      " [4.5 ]\n",
      " [6.75]\n",
      " [9.  ]] (5, 1)\n"
     ]
    }
   ],
   "source": [
    "array = np.linspace(0, 10-1, 10).reshape(-1, 1)\n",
    "resized = resize(array, 5)\n",
    "print(resized, resized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "class Sensor:\n",
    "    \"\"\"Object to process a 1D sensor signal.\n",
    "\n",
    "    For this to work well the data output by sensor_source should be a power\n",
    "    of vec_len.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sensor_source, vec_len, time_len, start=True):\n",
    "        \"\"\"Initialise sensor.\n",
    "\n",
    "        Arg:\n",
    "            sensor_source - SensorSource object that outputs a\n",
    "            vector of sensor readings when iterated.\n",
    "            vec_len - length of vector for VPU.\n",
    "            time_len - length of time buffering.\n",
    "        \"\"\"\n",
    "        self.source = sensor_source\n",
    "        self.vec_len = vec_len\n",
    "        self.time_len = time_len\n",
    "        # Variable to store time stages\n",
    "        self.stages = list()\n",
    "        # Variable to store nearest power length\n",
    "        self.power_len = None\n",
    "        # Variable to store original sensor length\n",
    "        self.sensor_len = None\n",
    "        # Start sensor by default\n",
    "        if start:\n",
    "            self.start()\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Start sensor.\"\"\"\n",
    "        self.source.start()\n",
    "        if not self.power_len:\n",
    "            _, initial_frame = self.source.read()\n",
    "            flattened = initial_frame.reshape(-1, 1)\n",
    "            self.sensor_len = flattened.shape[0]\n",
    "            num_stages = math.log(self.sensor_len, self.vec_len)\n",
    "            self.num_stages = int(num_stages)\n",
    "            self.power_len = self.vec_len**self.num_stages\n",
    "        # Build the time stages\n",
    "        self.build_stages()\n",
    "\n",
    "    def get_frame(self):\n",
    "        \"\"\"Get a 1D frame of data from the sensor.\"\"\"\n",
    "        # If the sensor is not started, start\n",
    "        if not self.source.started:\n",
    "            self.start()\n",
    "        # Get frame and flatten to 1D array\n",
    "        _, initial_frame = self.source.read()\n",
    "        flattened = initial_frame.reshape(-1, 1)\n",
    "        # Resize to nearest power of vec_len\n",
    "        output = resize(flattened, self.power_len)\n",
    "        return output\n",
    "\n",
    "    def generate_stage(self, stage_len):\n",
    "        \"\"\"Generate a stage.\n",
    "\n",
    "        Arg:\n",
    "            stage_len - integer number of stages.\n",
    "        \"\"\"\n",
    "        return TimeStage(self.vec_len, stage_len)\n",
    "\n",
    "    def build_stages(self):\n",
    "        \"\"\"Build a set of stages.\"\"\"\n",
    "        self.stages = [\n",
    "            self.generate_stage(\n",
    "                int(\n",
    "                    self.power_len / self.vec_len**(i+1)\n",
    "                )\n",
    "            )\n",
    "            for i in range(0, self.num_stages)\n",
    "        ]\n",
    "\n",
    "    def iterate(self):\n",
    "        \"\"\"High level processing loop.\"\"\"\n",
    "        input_data = self.get_frame()\n",
    "        for stage in self.stages:\n",
    "            stage.forward(input_data)\n",
    "            input_data = stage.get_causes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.227506780187165"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = math.log(312, 3); a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = Sensor(AudioSource(), 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sensor.stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sensor.get_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-20842.        ]\n",
      " [-19811.53571671]\n",
      " [-20396.81892697]\n",
      " ...\n",
      " [ 14271.91840537]\n",
      " [ 14416.11538071]\n",
      " [ 15861.        ]] (59049, 1)\n"
     ]
    }
   ],
   "source": [
    "print(data, data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.999999999999998"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.log(59049, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59049"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3**10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor.iterate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
