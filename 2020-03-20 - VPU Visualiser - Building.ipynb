{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll look at building a visualiser to view the VPU applied en-mass to FFT data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make our SensorSource objects iterables that return a next frame of data - https://www.programiz.com/python-programming/iterator ```__iter__``` just returns self (with any initialisation) and ```__next__``` returns self.read().\n",
    "\n",
    "Our SensorSource objects also need a way of returning the size of the frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sources.capture import VideoSource\n",
    "\n",
    "video = VideoSource()\n",
    "video.start()\n",
    "grabbed, frame = video.read()\n",
    "print(grabbed)\n",
    "\n",
    "video.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sources.capture import AudioSource\n",
    "import time\n",
    "\n",
    "audio = AudioSource()\n",
    "audio.start()\n",
    "time.sleep(0.5)\n",
    "# Test read\n",
    "length1, samples1 = audio.read()\n",
    "assert length1\n",
    "assert samples1.any()\n",
    "# Check starting and getting a frame\n",
    "audio.start()\n",
    "time.sleep(0.5)\n",
    "length2, samples2 = audio.read()\n",
    "assert length2\n",
    "assert not np.array_equal(samples1, samples2)\n",
    "# Test stopping\n",
    "audio.stop()\n",
    "assert not audio.started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.sources.capture import CombinedSource, SensorSource\n",
    "\n",
    "combined = CombinedSource()\n",
    "type(combined.sources) == dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined.sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(combined.sources) == dict\n",
    "assert len(combined.sources) == 0\n",
    "# Adding a source\n",
    "combined.add_source(SensorSource())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SensorSource'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(combined.sources.items())[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': array([     0,      0,      0, ..., -20308, -19527, -19405], dtype=int16), 'video': array([[[179, 175, 133],\n",
      "        [179, 175, 133],\n",
      "        [179, 175, 133],\n",
      "        ...,\n",
      "        [255, 251, 178],\n",
      "        [255, 248, 178],\n",
      "        [255, 248, 178]],\n",
      "\n",
      "       [[179, 174, 134],\n",
      "        [179, 174, 134],\n",
      "        [177, 175, 134],\n",
      "        ...,\n",
      "        [255, 251, 178],\n",
      "        [255, 249, 177],\n",
      "        [255, 249, 177]],\n",
      "\n",
      "       [[180, 175, 137],\n",
      "        [180, 175, 137],\n",
      "        [180, 175, 137],\n",
      "        ...,\n",
      "        [255, 252, 176],\n",
      "        [255, 251, 178],\n",
      "        [255, 251, 178]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[150, 136, 123],\n",
      "        [150, 136, 123],\n",
      "        [148, 137, 123],\n",
      "        ...,\n",
      "        [217, 193, 177],\n",
      "        [220, 192, 181],\n",
      "        [230, 202, 190]],\n",
      "\n",
      "       [[148, 133, 122],\n",
      "        [149, 134, 123],\n",
      "        [148, 133, 122],\n",
      "        ...,\n",
      "        [217, 190, 176],\n",
      "        [216, 190, 179],\n",
      "        [223, 197, 186]],\n",
      "\n",
      "       [[151, 130, 120],\n",
      "        [151, 130, 120],\n",
      "        [150, 134, 120],\n",
      "        ...,\n",
      "        [218, 181, 176],\n",
      "        [211, 182, 180],\n",
      "        [218, 189, 187]]], dtype=uint8)}\n"
     ]
    }
   ],
   "source": [
    "from src.sources.capture import AVCapture\n",
    "\n",
    "av = AVCapture()\n",
    "av.start()\n",
    "time.sleep(0.25)\n",
    "data = av.read()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
