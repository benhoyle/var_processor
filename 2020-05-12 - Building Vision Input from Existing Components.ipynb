{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Vision Input from Existing Components\n",
    "\n",
    "We have most of the code for processing vision from other projects. We just need to bring it together to make a video sensor.\n",
    "\n",
    "One thing we need to do is quickly process video input to convert to a 1D numpy array. \n",
    "\n",
    "Options:\n",
    "* Split visual field.\n",
    "* Lightness / colour (start with L).\n",
    "* Retinotopic mappings.\n",
    "* Area of interest.\n",
    "\n",
    "We'll look at square 2D blocks of sqrt(vec_len). Hence, vec_len is recommended to be a power of 4 - 4, 16 or 64. 4 and 16 are preferable to start.\n",
    "\n",
    "We have a ```VideoSource``` object. We might need to add a BGR to YUV step -  img_out = cv2.cvtColor(img_in, cv2.COLOR_BGR2YUV). In code I set the property 16 to 0 ```self.cam.set(16, 0)```. Ah - 16 indicates whether the image should be converted to RGB. 0 turns this off to get original YUV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile_array(a, b0, b1):\n",
    "    \"\"\"Tile array a in blocks of size b0 * b1\"\"\"\n",
    "    r, c = a.shape                                    # number of rows/columns\n",
    "    rs, cs = a.strides                                # row/column strides\n",
    "    x = as_strided(a, (r, b0, c, b1), (rs, 0, cs, 0)) # view as 4D array\n",
    "    return x.reshape(r*b0, c*b1)\n",
    "\n",
    "def separate_components(frame, square=True):\n",
    "    \"\"\"Separate frame into YUV components.\n",
    "\n",
    "    square - boolean - if true subsample the colour images so they are square\n",
    "    \"\"\"\n",
    "    if square:\n",
    "        return frame[:, :, 0], frame[::2, 1::2, 1], frame[::2, 0::2, 1]\n",
    "    else:\n",
    "        return frame[:, :, 0], frame[:, 1::2, 1], frame[:, 0::2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sources.video import VideoSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = VideoSource()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "_, frame = video.read()\n",
    "components = separate_components(frame, square=False)\n",
    "fig, axes = plt.subplots(3, 1)\n",
    "for ax, comp in zip(axes.ravel(), components):\n",
    "    ax.imshow(comp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "_, frame = video.read()\n",
    "components = separate_components(frame, square=True)\n",
    "fig, axes = plt.subplots(3, 1)\n",
    "for ax, comp in zip(axes.ravel(), components):\n",
    "    ax.imshow(comp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.imshow(frame[..., 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
